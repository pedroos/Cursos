If you take a 'population' of measurements, of anything. If you wanna know how the measurements distribute with a smaller sample of the population, you can employ methods to know whether you got a better or not so good quality measurement of the population from the sample. The more variable a sample is, that is, the more variation there is in its measurements, the less certain we are about it representing faithfully the population. Also, the smaller the sample we're working with, the smaller as well is the certainty about fidelity. (Which, from a logical perspective, seems to make sense: if we are looking at only a few samples from a large population, the more probability there is that they may be irregular samples which give us wrong estimates. The larger the sample we use, the more the unevenness tends to 'spread out' and the reflect the final evenness character of the population as a whole.) Inferential statistics is about putting numbers in this 'uncertainty': the more we want to be sure of our measurement from a sample, the larger the sample and/or the smaller the variation we need to accept to trust our result. The more we are willing to accept less trusty results, the smaller and/or more irregular samples we can use (often a factor in real-world measurements, where the samples are results of interviews conducted with a determined number of people, for example).

In statistical inference, we specify a number for how certain we want to be, and then adjust our sample size and/or variation, or from an already captured sample, infer whether it meets the certainty number; or we choose a range for what we the measurement must look like from the sample; and then we check with what certainty we can affirm that range to be the real one in the population (it could be 0%, or it could be 100%).

For example, what is the probability that a random human being in the world is going to live for 100 years? The larger the longevity data we look at to calculate the value (the mean of the measurements), the more certain we can be that it represents the human beings of the world as a whole. Also, if we collect two samples, and one sample shows variations like longevity ranging from 60 to 120; and another sample shows variation like from 80 to 90, and the samples have the same size, then we can know that we can trust the sample with the smaller variation more. (It is simply less probable that less uniform data is more accurate.)

If we want to put a number on the certainty we want to have of the results, we can say something like: 'I want to have 90% certainty about the longevity of the human population as a whole.' Then, we calculate what size sample and/or how variable the sample must be, find a sample that meets the criteria (either from the size or variability criteria, or both), and read its value with 90% confidence. Or, if we have a sample and want to determine whether it meets the confidence number we've stipulated, we check its size and/or variation and then determine whether it passes the confidence test.

We may want to look at what range of values we would get from a certain certainty number. For example, we may want to say 'I have seen that in this sample, the mean of the values is 89.5 years. Given the characteristics of the sample, or, in other words, looking at its size and variability, what can we say with 95% of certainty the interval in the population is?' We could calculate, for example, that, based on the sample, it is 95% probable that the margin of error around the measure value (89.5) is of 5 years (that is, 89.5 plus or minus 5 years or from 84.5 to 94.5 years). If we want to be less certain, we can be sure that the interval we'll find will be tighter; the more specific the number we're looking to arrive at, the more we can know that it's less certain that is just the right value; we might be missing the mark by the intrinsic quality of our sample, or simply by chance. However, if we want to accept less uncertainty, we'll know the range of the number we get at will be more spread out.

Statistical inference includes formulas and tried-and-true recipes for questions like, which distributions to choose to describe different phenomena, or what corrections to apply to compensate for unusual conditions of measurement that may distort our results, with a aim to always arrive at the most valid possible values for our uses.

This is my humble description of statistical inference (that I wish I've had at the beginning of my textbook when I first had contact with it -- instead of formulas, Greek symbols and extremely weird names for remarkably uncomplicated objects.)