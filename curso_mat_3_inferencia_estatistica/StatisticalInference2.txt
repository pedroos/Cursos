An Introductory Preface to Inferential Statistics
If you (yes, you!) take a 'population' of measurements, and want to know how the measurements distribute from reviewing just a portion of said population, you can employ methods to know whether you got a good or not so good quality measurement from the sample. The more variable a sample is, that is, the more dispersion there is in the sample's measurements, the less certainty there can be about it representing faithfully the population value. The smaller the sample, the smaller, as well, the certainty about its fidelity towards the population.
Which, from a logical perspective, makes sense: by looking at only a few samples from a large population, the more probability there has to be that these samples may be irregular, or atypical, samples, which give back wrong estimates. The more the sample size is increased, the more the unevenness is, to say it in metaphorical words, 'diluted' inside the totality of the sample, and the higher the expectation that the sample reflects, in truth, the actual population parameter.
Inferential statistics is a collection of methods for assigning a number to this 'uncertainty': the more we want to be sure of the precision of a sample measurement, the larger the sample or smaller the variation we must accept, in turn, to trust the result. The more we can accept a lesser amount of trust, the smaller or more irregular the samples we can then proceed to use or obtain. (As is known, sample size can be a limiting factor in real-world measurements, when logistic considerations may impede sample sizes larger than some specific number from being attained).
In Statistical Inference, we specify a number for how certain we want to be, and then adjust our sample size and/or variation, or from an already captured sample, infer whether it meets the certainty number; or we choose a range for what we the measurement must look like from the sample; and then we check with what certainty we can affirm that range to be the real one in the population (it could be 0%, or it could be 100%).

For example, what is the probability that a random human being in the world is going to live for 100 years? The larger the longevity data we succeed in collecting to calculate the value (which is, actually, the mean of the measurements), the more certain we can be that it represents the human beings of the world as a whole. Also, if we collect two samples, and one sample shows variations like longevity ranging from 60 to 120, and another sample shows variation like from 80 to 90, and the samples have the same size, then we can know that we can trust the sample with the smaller variation more. (It is simply less probable that less uniform data is more accurate.)
If we want to put a number on the certainty we want to have of the results, we can say something like:
I want to have 90% certainty about the longevity number of the human population on this planet.
To achieve that, we 1) calculate what size sample and/or how variable the sample must be; 2) find a sample that meets the criteria (either from the size or variability criteria, or both), and 3) read its value with 90% confidence. Or, in the transverse case, if we have a sample and want to determine whether it meets the confidence number stipulated, we: 1) check its size and/or variation;  and 2) determine whether it passes the confidence test.
Called hypothesis testing.
We may want, also, to look at what range of values we would get from a certain certainty number. For example, we may want to say, 
I have verified that in this sample, the mean of the values is 89.5 years. Given the characteristics of the sample, or, in other words; looking at its size and variability, what can we say with 95% of certainty about what the interval found in the population is?
It could be calculated, for example, that, based on that particular sample, it is 95% probable that the margin of error around the measure value (89.5) is of 5 years; that is, 89.5 plus or minus 5 years, or from 84.5 to 94.5 years.
If we choose to be less certain, we can be sure that the interval we'll find will be tighter; the more specific the number we're looking to arrive at, the more we can know that it's less certain that is just the right value. We might be missing the mark by the intrinsic quality of our sample, or we might be missing it simply by chance. However, if we want to accept less uncertainty, we'll know the range of the number we get at will be a larger range.
Say 'hello' to interval estimation.
Statistical inference includes formulas and tried-and-true recipes for variables and problems like, which distributions to choose to describe different phenomena?, or, what corrections to apply to compensate for unusual conditions of measurement that may distort results?, with an objective to arrive at the most valid possible values determinable from our experiments.
Such as this I close a tentative explanation I may say I wish I would have come across around the time the beginning of Statistical Inference class  as Math student  -  instead of a barrage of formulas, Greek symbols and (totally) non-descriptive names, for objects which are in the end not that complicated - which maybe would have made me feel quicker at home, or, at least, bearing a map to it.