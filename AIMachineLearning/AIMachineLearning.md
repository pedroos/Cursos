Coursera Probability for Data Science
- Probability Definitions and Notation
- Joint Probabilities
- Permutations and Combinations1
- Using Factorial and “M choose N”
- The Sum Rule, Conditional Probability, and the Product Rule
- Bayes’ Theorem (Part 1)
- Bayes’ Theorem (Part 2)
- The Binomial Theorem and Bayes Theorem

https://www.coursera.org/learn/ibm-ai-workflow-machine-learning-vr-nlp

Bayesian Deep Learning, Probabilistic machine learning, Computer Vision, Uncertainty-aware Deep Learning, Uncertainty calibration, Multimodal fusion, Adversarial machine learning, Reliable and Robust machine learning, principled reasoning in AI systems.

Modern neural networks are typically overconfident.

Hidden layer is a layer of nodes between input and output nodes.

Multiple hidden layers are what "deep learning" refers to.

> The GPT-f work from OpenAI about using transformers to do theorem proving on the Metamath corpus is relevant. There, they investigate whether deep neural networks can learn the properties of the proof-distribution space to help speed up automatic theorem proving, with some success.
> https://arxiv.org/abs/2009.03393